{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Prepare models for visualization (generation of Doc.js file) - 10 topics</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, os, re, time\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.test.utils import datapath\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible results\n",
    "random_state = 33\n",
    "# if the test is True, the process runs on a smaller subset of raw data (json files)\n",
    "test = False\n",
    "\n",
    "if test:\n",
    "    # path where the doc files are stored\n",
    "    path_doc = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins_test\\doc'\n",
    "    # path where the meta files are stored\n",
    "    path_meta = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins_test\\meta'\n",
    "    # path where all the files related to the visualization of the models are stored\n",
    "    path_viz = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins_test\\viz'\n",
    "else:\n",
    "    # path where the doc files are stored\n",
    "    path_doc = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins\\doc'\n",
    "    # path where the meta files are stored\n",
    "    path_meta = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins\\meta'\n",
    "    # path where all the files related to the visualization of the models are stored\n",
    "    path_viz = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins\\viz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove \" from original documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_content_viz(path_doc, yyyy_MMM):\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    file_doc = os.path.join(path_doc, yyyy_MMM, yyyy_MMM)\n",
    "    df_doc = pd.read_csv(file_doc + '.csv', names=['id_doc', 'content'])\n",
    "\n",
    "    # generate regular expression pattern\n",
    "    re_pattern = r'(\")'\n",
    "    df_doc['content'] = df_doc['content'].apply(lambda x: re.sub(re_pattern, '', str(x)))\n",
    "    df_doc.to_csv(file_doc + '_viz.csv', index=False, header=False)\n",
    "\n",
    "    time_end = time.time()\n",
    "    hour, rem = divmod(time_end - time_start, 3600)\n",
    "    minute, second = divmod(rem, 60)\n",
    "    print('documents_content_viz - time elapsed - {:0>2}:{:0>2}:{:05.2f}'.format(int(hour), int(minute), second))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function get documents metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_viz(doc_js, path_doc, path_meta, yyyy_MMM):\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    file_doc = os.path.join(path_doc, yyyy_MMM, yyyy_MMM)\n",
    "    df_doc = pd.read_csv(file_doc + '_viz.csv', names=['id_doc', 'content'])\n",
    "\n",
    "    file_meta = os.path.join(path_meta, yyyy_MMM, yyyy_MMM)\n",
    "    df_meta = pd.read_csv(file_meta + '.csv', names=['id_meta', 'file', 'author_followers', 'author_full_name', 'author_id', 'author_image', 'author_name', 'author_url', 'date', 'date_from_provider', 'id', 'id_from_provider', 'image_url', 'link', 'location_latitude', 'location_longitude', 'place_country_code', 'place_name', 'place_street_address', 'provider', 'social_likes', 'social_replies'])\n",
    "\n",
    "    df_merged = pd.merge(left=df_doc, right=df_meta, left_on='id_doc', right_on='id_meta')\n",
    "\n",
    "    file_viz = os.path.join(path_viz, 'doc_id_2_doc_id_viz')\n",
    "    df_viz = pd.read_csv(file_viz + '.csv')\n",
    "    \n",
    "    df_merged = pd.merge(left=df_merged, right=df_viz, left_on='id_doc', right_on='doc_id')\n",
    "    df_merged = df_merged.sort_values(by='doc_id_viz', ascending=True)\n",
    "    for i ,(index, row) in enumerate(df_merged.iterrows()):\n",
    "        doc_js = doc_js + '\"' + str(int(row['id_doc'])) + '\": {\"tweet_id\": ' + str(int(row['doc_id_viz'])) + ', \"author\": \"' + str(row['author_full_name']) + '\", \"tweet_date\": \"' + dateutil.parser.parse(str(row['date'])).strftime(\"%#m/%#d/%Y %#H:%#M\") + '\", \"text\": \"' + str(row['content']) + '\", \"author_url\": \"' + str(row['author_url']) + '\"},'\n",
    "\n",
    "    time_end = time.time()\n",
    "    hour, rem = divmod(time_end - time_start, 3600)\n",
    "    minute, second = divmod(rem, 60)\n",
    "    print('documents_viz - time elapsed - {:0>2}:{:0>2}:{:05.2f}'.format(int(hour), int(minute), second))\n",
    "    \n",
    "    return doc_js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function get documents metadata (for last month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_viz_last(doc_js, path_doc, path_meta, yyyy_MMM):\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    file_doc = os.path.join(path_doc, yyyy_MMM, yyyy_MMM)\n",
    "    df_doc = pd.read_csv(file_doc + '_viz.csv', names=['id_doc', 'content'])\n",
    "\n",
    "    file_meta = os.path.join(path_meta, yyyy_MMM, yyyy_MMM)\n",
    "    df_meta = pd.read_csv(file_meta + '.csv', names=['id_meta', 'file', 'author_followers', 'author_full_name', 'author_id', 'author_image', 'author_name', 'author_url', 'date', 'date_from_provider', 'id', 'id_from_provider', 'image_url', 'link', 'location_latitude', 'location_longitude', 'place_country_code', 'place_name', 'place_street_address', 'provider', 'social_likes', 'social_replies'])\n",
    "\n",
    "    df_merged = pd.merge(left=df_doc, right=df_meta, left_on='id_doc', right_on='id_meta')\n",
    "\n",
    "    file_viz = os.path.join(path_viz, 'doc_id_2_doc_id_viz')\n",
    "    df_viz = pd.read_csv(file_viz + '.csv')\n",
    "    \n",
    "    df_merged = pd.merge(left=df_merged, right=df_viz, left_on='id_doc', right_on='doc_id')\n",
    "    df_merged = df_merged.sort_values(by='doc_id_viz', ascending=True)\n",
    "    for i ,(index, row) in enumerate(df_merged.iterrows()):\n",
    "        if i < len(df_merged) - 1:\n",
    "            doc_js = doc_js + '\"' + str(int(row['id_doc'])) + '\": {\"tweet_id\": ' + str(int(row['doc_id_viz'])) + ', \"author\": \"' + str(row['author_full_name']) + '\", \"tweet_date\": \"' + dateutil.parser.parse(str(row['date'])).strftime(\"%#m/%#d/%Y %#H:%#M\") + '\", \"text\": \"' + str(row['content']) + '\", \"author_url\": \"' + str(row['author_url']) + '\"},'\n",
    "        else:\n",
    "            doc_js = doc_js + '\"' + str(int(row['id_doc'])) + '\": {\"tweet_id\": ' + str(int(row['doc_id_viz'])) + ', \"author\": \"' + str(row['author_full_name']) + '\", \"tweet_date\": \"' + dateutil.parser.parse(str(row['date'])).strftime(\"%#m/%#d/%Y %#H:%#M\") + '\", \"text\": \"' + str(row['content']) + '\", \"author_url\": \"' + str(row['author_url']) + '\"}'\n",
    "\n",
    "    time_end = time.time()\n",
    "    hour, rem = divmod(time_end - time_start, 3600)\n",
    "    minute, second = divmod(rem, 60)\n",
    "    print('documents_viz - time elapsed - {:0>2}:{:0>2}:{:05.2f}'.format(int(hour), int(minute), second))\n",
    "    \n",
    "    return doc_js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Generate Doc.js file</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_js = 'function populate_tweets_Instagram_2019(){var tweet_data ={'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 2019_Jan -----\n",
      "documents_content_viz - time elapsed - 00:00:02.92\n",
      "documents_viz - time elapsed - 01:07:52.53\n",
      "----- 2019_Feb -----\n",
      "documents_content_viz - time elapsed - 00:00:03.32\n",
      "documents_viz - time elapsed - 00:00:03.27\n",
      "----- 2019_Mar -----\n",
      "documents_content_viz - time elapsed - 00:00:04.20\n",
      "documents_viz - time elapsed - 00:00:05.06\n",
      "----- 2019_Apr -----\n",
      "documents_content_viz - time elapsed - 00:00:04.47\n",
      "documents_viz - time elapsed - 00:00:06.99\n",
      "----- 2019_May -----\n",
      "documents_content_viz - time elapsed - 00:00:05.22\n",
      "documents_viz - time elapsed - 00:00:05.35\n",
      "----- 2019_Jun -----\n",
      "documents_content_viz - time elapsed - 00:00:04.96\n",
      "documents_viz - time elapsed - 00:00:05.06\n",
      "----- 2019_Jul -----\n",
      "documents_content_viz - time elapsed - 00:00:02.45\n",
      "documents_viz - time elapsed - 00:00:03.19\n",
      "----- 2019_Aug -----\n",
      "documents_content_viz - time elapsed - 00:00:03.35\n",
      "documents_viz - time elapsed - 00:00:04.11\n",
      "----- 2019_Sep -----\n",
      "documents_content_viz - time elapsed - 00:00:04.23\n",
      "documents_viz - time elapsed - 00:00:04.73\n",
      "----- 2019_Oct -----\n",
      "documents_content_viz - time elapsed - 00:00:05.06\n",
      "documents_viz - time elapsed - 00:00:05.06\n",
      "----- 2019_Nov -----\n",
      "documents_content_viz - time elapsed - 00:00:04.83\n",
      "documents_viz - time elapsed - 00:00:05.06\n",
      "----- 2019_Dec -----\n",
      "documents_content_viz - time elapsed - 00:00:04.68\n",
      "documents_viz - time elapsed - 00:00:05.45\n"
     ]
    }
   ],
   "source": [
    "yyyy_MMM = '2019_Jan'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Feb'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Mar'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Apr'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_May'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Jun'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Jul'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Aug'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Sep'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Oct'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Nov'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz(doc_js, path_doc, path_meta, yyyy_MMM)\n",
    "\n",
    "yyyy_MMM = '2019_Dec'\n",
    "print('----- ' + yyyy_MMM + ' -----')\n",
    "documents_content_viz(path_doc, yyyy_MMM)\n",
    "doc_js = documents_viz_last(doc_js, path_doc, path_meta, yyyy_MMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_js = doc_js + '};readTweetJSON(tweet_data);}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_viz = os.path.join(path_viz, 'Doc.js')\n",
    "\n",
    "with open(file_viz, 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(doc_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
