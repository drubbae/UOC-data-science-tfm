{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Load data (files in folder influencers_1_de_2)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to load the raw data provided; inside folders **\\data\\influencers_1_de_2** and **\\data\\influencers_2_de_2**.  \n",
    "  \n",
    "This code generates several folders depending on the year and month of the document. Inside the folder named **data\\bins\\**, several subfolders are created with the following name structure **doc\\yyyy_MMM\\** and **meta\\yyyy_MMM\\**.  \n",
    "  \n",
    "The files inside the **doc** subfolders contain the text of the messages from Instagram.  \n",
    "\n",
    "The files inside the **meta** subfolders contain the metadata (date, author name, likes, etc.) of the messages from Instagram.  \n",
    "    \n",
    "Inside these **yyyy_MMM** subfolders a **csv** file with the same name structure is created **yyyy_MMM.csv**.  \n",
    "  \n",
    "The final structure of folders and files will be:  \n",
    "- data\\bins\\doc\\2019_Jan\\2019_Jan.csv  \n",
    "- data\\bins\\doc\\2019_Feb\\2019_Feb.csv  \n",
    "- ...  \n",
    "- data\\bins\\doc\\2019_Nov\\2019_Nov.csv  \n",
    "- data\\bins\\doc\\2019_Dec\\2019_Dec.csv  \n",
    "  \n",
    "  \n",
    "- data\\bins\\meta\\2019_Jan\\2019_Jan.csv  \n",
    "- data\\bins\\meta\\2019_Feb\\2019_Feb.csv  \n",
    "- ...  \n",
    "- data\\bins\\meta\\2019_Nov\\2019_Nov.csv  \n",
    "- data\\bins\\meta\\2019_Dec\\2019_Dec.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Jokiph3r/Jsonl-to-csv/blob/master/jsonl-to-csv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, glob, json, os\n",
    "import pandas as pd\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if debug is True, messages during the process are generated\n",
    "debug = False\n",
    "# if the test is True, the process runs on a smaller subset of raw data (json files)\n",
    "test = False\n",
    "# first id value to be assaigned \n",
    "id = 0\n",
    "\n",
    "month_index_list = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths (input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data - path jsonl files\n",
    "if test:\n",
    "    input_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\influencers_test_1_de_2'\n",
    "else:\n",
    "    input_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\influencers_1_de_2'\n",
    "\n",
    "# output data - path where the csv file is generated\n",
    "if test:\n",
    "    output_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins_test'\n",
    "else:\n",
    "    output_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id -  1607742\n"
     ]
    }
   ],
   "source": [
    "# reading all jsonl files\n",
    "files = [f for f in glob.glob(input_path + \"**/*.jsonl\", recursive=True)]\n",
    "\n",
    "for f in files:\n",
    "    with open(f, mode='r') as file:\n",
    "        for line in file:\n",
    "            # flatten json files\n",
    "            data = json.loads(line)\n",
    "            data_flatten = flatten(data)\n",
    "            # debug line to check the progress while executing\n",
    "            if debug:\n",
    "                print(line, data_flatten)\n",
    "            # check if document subfolder doc\\yyyy_mmm exists, if not create it\n",
    "            if not os.path.exists(os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1])):\n",
    "                os.makedirs(os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]))\n",
    "            # check if metadata subfolder meta\\yyyy_mmm exists, if not create it\n",
    "            if not os.path.exists(os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1])):\n",
    "                os.makedirs(os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]))\n",
    "            # increment id (to link document and metadata folders/files)\n",
    "            id += 1\n",
    "            # creating doc csv file\n",
    "            path = os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]) + '\\\\' + str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1] + '.csv'\n",
    "            with open(path, mode='a', newline='', encoding='utf-8') as f1:\n",
    "                csv_writer = csv.writer(f1)\n",
    "                csv_writer.writerow([\n",
    "                    id,\n",
    "                    data_flatten['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "                ])\n",
    "            # creating meta csv file\n",
    "            path = os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]) + '\\\\' + str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1] + '.csv'\n",
    "            with open(path, mode='a', newline='', encoding='utf-8') as f2:\n",
    "                csv_writer = csv.writer(f2)\n",
    "                csv_writer.writerow([\n",
    "                    id,\n",
    "                    file,\n",
    "                    data_flatten['author_followers'],\n",
    "                    data_flatten['author_full_name'],\n",
    "                    data_flatten['author_id'],\n",
    "                    data_flatten['author_image'],\n",
    "                    data_flatten['author_name'],\n",
    "                    data_flatten['author_url'],\n",
    "                    data_flatten['date'],\n",
    "                    data_flatten['date_from_provider'],\n",
    "                    data_flatten['id'],\n",
    "                    data_flatten['id_from_provider'],\n",
    "                    data_flatten['image_url'],\n",
    "                    data_flatten['link'],\n",
    "                    data_flatten['location_latitude'],\n",
    "                    data_flatten['location_longitude'],\n",
    "                    data_flatten['place_country_code'],\n",
    "                    data_flatten['place_name'],\n",
    "                    data_flatten['place_street_address'],\n",
    "                    data_flatten['provider'],\n",
    "                    data_flatten['social_likes'],\n",
    "                    data_flatten['social_replies']\n",
    "                ])\n",
    "                \n",
    "print('id - ', str(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Load data (files in folder influencers_2_de_2)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths (input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data - path jsonl files\n",
    "if test:\n",
    "    input_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\influencers_test_2_de_2'\n",
    "else:\n",
    "    input_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\influencers_2_de_2'\n",
    "\n",
    "# output data - path where the csv file is generated\n",
    "if test:\n",
    "    output_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins_test'\n",
    "else:\n",
    "    output_path = r'D:\\master\\data science\\semestre 4\\M2.979 - tfm\\data\\bins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id -  3257290\n"
     ]
    }
   ],
   "source": [
    "# reading all jsonl files\n",
    "files = [f for f in glob.glob(input_path + \"**/*.jsonl\", recursive=True)]\n",
    "\n",
    "for f in files:\n",
    "    with open(f, mode='r') as file:\n",
    "        for line in file:\n",
    "            # flatten json files\n",
    "            data = json.loads(line)\n",
    "            data_flatten = flatten(data)\n",
    "            # debug line to check the progress while executing\n",
    "            if debug:\n",
    "                print(line, data_flatten)\n",
    "            # check if document subfolder doc\\yyyy_mmm exists, if not create it\n",
    "            if not os.path.exists(os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1])):\n",
    "                os.makedirs(os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]))\n",
    "            # check if metadata subfolder meta\\yyyy_mmm exists, if not create it\n",
    "            if not os.path.exists(os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1])):\n",
    "                os.makedirs(os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]))\n",
    "            # increment id (to link document and metadata folders/files)\n",
    "            id += 1\n",
    "            # creating doc csv file\n",
    "            path = os.path.join(output_path, 'doc', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]) + '\\\\' + str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1] + '.csv'\n",
    "            with open(path, mode='a', newline='', encoding='utf-8') as f1:\n",
    "                csv_writer = csv.writer(f1)\n",
    "                csv_writer.writerow([\n",
    "                    id,\n",
    "                    data_flatten['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "                ])\n",
    "            # creating meta csv file\n",
    "            path = os.path.join(output_path, 'meta', str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1]) + '\\\\' + str((pd.to_datetime(data_flatten['date'])).year) + '_' + month_index_list[(pd.to_datetime(data_flatten['date'])).month - 1] + '.csv'\n",
    "            with open(path, mode='a', newline='', encoding='utf-8') as f2:\n",
    "                csv_writer = csv.writer(f2)\n",
    "                csv_writer.writerow([\n",
    "                    id,\n",
    "                    file,\n",
    "                    data_flatten['author_followers'],\n",
    "                    data_flatten['author_full_name'],\n",
    "                    data_flatten['author_id'],\n",
    "                    data_flatten['author_image'],\n",
    "                    data_flatten['author_name'],\n",
    "                    data_flatten['author_url'],\n",
    "                    data_flatten['date'],\n",
    "                    data_flatten['date_from_provider'],\n",
    "                    data_flatten['id'],\n",
    "                    data_flatten['id_from_provider'],\n",
    "                    data_flatten['image_url'],\n",
    "                    data_flatten['link'],\n",
    "                    data_flatten['location_latitude'],\n",
    "                    data_flatten['location_longitude'],\n",
    "                    data_flatten['place_country_code'],\n",
    "                    data_flatten['place_name'],\n",
    "                    data_flatten['place_street_address'],\n",
    "                    data_flatten['provider'],\n",
    "                    data_flatten['social_likes'],\n",
    "                    data_flatten['social_replies']\n",
    "                ])\n",
    "                \n",
    "print('id - ', str(id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
